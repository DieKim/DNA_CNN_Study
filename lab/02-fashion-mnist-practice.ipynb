{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keras fashion mnist dataset을 다운로드\n* 5만개의 학습용, 1만개의 테스트용 grayscale image array를 다운로드","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n# image size는 28x28의 grayscale 2차원 데이터\nprint(\"train dataset shape:\", train_images.shape, train_labels.shape)\nprint(\"test dataset shape:\", test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:03:55.741072Z","iopub.execute_input":"2021-07-05T13:03:55.74177Z","iopub.status.idle":"2021-07-05T13:04:03.706015Z","shell.execute_reply.started":"2021-07-05T13:03:55.741673Z","shell.execute_reply":"2021-07-05T13:04:03.70513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MNIST image array 시각화","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(train_images[0], cmap='gray')\nplt.title(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:04:13.063541Z","iopub.execute_input":"2021-07-05T13:04:13.063889Z","iopub.status.idle":"2021-07-05T13:04:13.219166Z","shell.execute_reply.started":"2021-07-05T13:04:13.06386Z","shell.execute_reply":"2021-07-05T13:04:13.218506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0, :, :], train_labels[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:04:28.482982Z","iopub.execute_input":"2021-07-05T13:04:28.483339Z","iopub.status.idle":"2021-07-05T13:04:28.49156Z","shell.execute_reply.started":"2021-07-05T13:04:28.483305Z","shell.execute_reply":"2021-07-05T13:04:28.49064Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline \n\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\ndef show_images(images, labels, ncols=8):\n    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        axs[i].imshow(images[i], cmap='gray')\n        axs[i].set_title(class_names[labels[i]])\n        \nshow_images(train_images[:8], train_labels[:8], ncols=8)\nshow_images(train_images[8:16], train_labels[8:16], ncols=8)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:05:18.742962Z","iopub.execute_input":"2021-07-05T13:05:18.743355Z","iopub.status.idle":"2021-07-05T13:05:20.050649Z","shell.execute_reply.started":"2021-07-05T13:05:18.743317Z","shell.execute_reply":"2021-07-05T13:05:20.049559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 전처리 수행. \n* 0 ~ 255 사이의 픽셀값을 0 ~ 1 사이 값으로 변환. \n* array type은 float 32","metadata":{}},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)\n\nprint(\"train dataset shape:\", train_images.shape, train_labels.shape)\nprint(\"test dataset shape:\", test_images.shape, test_labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:08:31.796706Z","iopub.execute_input":"2021-07-05T13:08:31.797062Z","iopub.status.idle":"2021-07-05T13:08:32.504568Z","shell.execute_reply.started":"2021-07-05T13:08:31.797032Z","shell.execute_reply":"2021-07-05T13:08:32.503865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:12:41.341921Z","iopub.execute_input":"2021-07-05T13:12:41.342301Z","iopub.status.idle":"2021-07-05T13:12:41.355275Z","shell.execute_reply.started":"2021-07-05T13:12:41.342263Z","shell.execute_reply":"2021-07-05T13:12:41.354518Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dense Layer를 기반으로 모델을 생성","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 28","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_SIZE = 28","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:13:02.391896Z","iopub.execute_input":"2021-07-05T13:13:02.392426Z","iopub.status.idle":"2021-07-05T13:13:02.397014Z","shell.execute_reply.started":"2021-07-05T13:13:02.392383Z","shell.execute_reply":"2021-07-05T13:13:02.39597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential([\n    # input_shape=(60000, INPUT_SIZE, INPUT_SIZE)가 아닌 이유 정확히 이해!\n    # <=> Output Shape가 (None, )으로 나오는 이유\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)), # Flatten: Dense -> 1차원으로 만들어줘야 함\n    Dense(100, activation='relu'), # Dense Layer: Weighted Sum + Activation(생략 가능) -> Output \n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax') \n])\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:13:02.700968Z","iopub.execute_input":"2021-07-05T13:13:02.701308Z","iopub.status.idle":"2021-07-05T13:13:02.814911Z","shell.execute_reply.started":"2021-07-05T13:13:02.70128Z","shell.execute_reply":"2021-07-05T13:13:02.813724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 모델의 Loss와 Optimizer 설정하고 학습 수행\n* loss는 categorical_crossentropy로, optimizer는 Adam으로 설정\n* categorical crossentropy를 위해서 Lable을 OHE 로 변경","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:16:01.945712Z","iopub.execute_input":"2021-07-05T13:16:01.946084Z","iopub.status.idle":"2021-07-05T13:16:01.960977Z","shell.execute_reply.started":"2021-07-05T13:16:01.946055Z","shell.execute_reply":"2021-07-05T13:16:01.960032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\n# categorical_crossentropy -> 반드시 one-hot encoding\ntrain_oh_labels = to_categorical(train_labels)\ntest_oh_labels = to_categorical(test_labels)\n\nprint(train_oh_labels.shape, test_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:16:46.114167Z","iopub.execute_input":"2021-07-05T13:16:46.114521Z","iopub.status.idle":"2021-07-05T13:16:46.123902Z","shell.execute_reply.started":"2021-07-05T13:16:46.114491Z","shell.execute_reply":"2021-07-05T13:16:46.122886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:16:46.539435Z","iopub.execute_input":"2021-07-05T13:16:46.539816Z","iopub.status.idle":"2021-07-05T13:16:46.545438Z","shell.execute_reply.started":"2021-07-05T13:16:46.539785Z","shell.execute_reply":"2021-07-05T13:16:46.544617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=train_images, y=train_oh_labels, batch_size=32, epochs=20, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:16:53.065694Z","iopub.execute_input":"2021-07-05T13:16:53.066056Z","iopub.status.idle":"2021-07-05T13:17:47.892122Z","shell.execute_reply.started":"2021-07-05T13:16:53.066023Z","shell.execute_reply":"2021-07-05T13:17:47.890909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:21:58.338911Z","iopub.execute_input":"2021-07-05T13:21:58.339335Z","iopub.status.idle":"2021-07-05T13:21:58.344766Z","shell.execute_reply.started":"2021-07-05T13:21:58.339297Z","shell.execute_reply":"2021-07-05T13:21:58.343895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터를 기반으로 Label 값 예측\n* model.predict()를 이용하여 label값 예측\n* predict()의 인자로 입력되는 feature array는 학습의 feature array와 shape가 동일해야함. \n* fit() 시 3차원(28x28 2차원 array가 여러개 존재) array 입력 했으므로 predict()도 동일한 3차원 데이터 입력\n* 특히 한건만 predict() 할때도 3차원 데이터여야 함. 이를 위해 expand_dims()로 2차원 image 배열을 3차원으로 변경","metadata":{}},{"cell_type":"code","source":"# 3차원\ntest_images.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:22:42.609115Z","iopub.execute_input":"2021-07-05T13:22:42.609519Z","iopub.status.idle":"2021-07-05T13:22:42.615875Z","shell.execute_reply.started":"2021-07-05T13:22:42.609478Z","shell.execute_reply":"2021-07-05T13:22:42.61457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(test_images)\nprint(pred_proba.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:22:46.353965Z","iopub.execute_input":"2021-07-05T13:22:46.35432Z","iopub.status.idle":"2021-07-05T13:22:46.694986Z","shell.execute_reply.started":"2021-07-05T13:22:46.354285Z","shell.execute_reply":"2021-07-05T13:22:46.694244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2차원 -> 3차원으로 바꿔줘야 함 \nnp.expand_dims(test_images[0], axis=0).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:23:52.591305Z","iopub.execute_input":"2021-07-05T13:23:52.591719Z","iopub.status.idle":"2021-07-05T13:23:52.598009Z","shell.execute_reply.started":"2021-07-05T13:23:52.591685Z","shell.execute_reply":"2021-07-05T13:23:52.596765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(np.expand_dims(test_images[0], axis=0)) # 헷갈리기 쉬움\nprint('softmax output:', pred_proba)\npred = np.argmax(np.squeeze(pred_proba)) # np.squeeze: 다시 필요없는 차원 다운\nprint('predicted class value:', pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:25:18.585899Z","iopub.execute_input":"2021-07-05T13:25:18.586288Z","iopub.status.idle":"2021-07-05T13:25:18.629682Z","shell.execute_reply.started":"2021-07-05T13:25:18.586252Z","shell.execute_reply":"2021-07-05T13:25:18.628642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nprint('target class value:', test_labels[0], 'predicted class value:', pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:26:04.925147Z","iopub.execute_input":"2021-07-05T13:26:04.925666Z","iopub.status.idle":"2021-07-05T13:26:04.931743Z","shell.execute_reply.started":"2021-07-05T13:26:04.925632Z","shell.execute_reply":"2021-07-05T13:26:04.930604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터 세트로 모델 성능 검증","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_images, test_oh_labels, batch_size=64) # 역시 one_hot encoding 된 값을 넣어줘야 함 ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:26:45.687713Z","iopub.execute_input":"2021-07-05T13:26:45.688037Z","iopub.status.idle":"2021-07-05T13:26:46.083343Z","shell.execute_reply.started":"2021-07-05T13:26:45.68801Z","shell.execute_reply":"2021-07-05T13:26:46.082503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 검증 데이터 세트를 이용하여 학습 수행. \n* 일반적으로 fit() 수행시 별도의 검증 데이터 세트를 이용하여 학습 시 과적합(Overfitting)이 발생하는지 모니터링\n* fit()을 수행하면 iteration을 반복하기 때문에 중간에 하이퍼파라미터 변경(예: Learning Rate)등의 작업이 어려움. \n* fit() iteration시 여러 작업을 하기 위해 Callback 객체를 가짐. \n* 검증 데이터 세트를 fit() 시 적용하여 과적합이나 더이상 검증 데이터 성능이 좋아 지지 않을 때 Callback을 사용하여 Learning Rate 보정 작업등을 수행 가능","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom tensorflow.keras.datasets import fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:30:19.940207Z","iopub.execute_input":"2021-07-05T13:30:19.940496Z","iopub.status.idle":"2021-07-05T13:30:30.385309Z","shell.execute_reply.started":"2021-07-05T13:30:19.940429Z","shell.execute_reply":"2021-07-05T13:30:30.384515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# 기존 학습 데이터를 다시 학습과 검증 데이터 세트로 분리\ntr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.15, random_state=2021)\nprint('train과 validation shape:', tr_images.shape, tr_labels.shape, val_images.shape, val_labels.shape)\n\n# OHE 적용\ntr_oh_labels = to_categorical(tr_labels)\nval_oh_labels = to_categorical(val_labels)\n\nprint('after OHE:', tr_oh_labels.shape, val_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:30:55.656089Z","iopub.execute_input":"2021-07-05T13:30:55.656405Z","iopub.status.idle":"2021-07-05T13:30:56.267865Z","shell.execute_reply.started":"2021-07-05T13:30:55.656378Z","shell.execute_reply":"2021-07-05T13:30:56.26713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 검증 데이터 세트를 적용하여 학습 수행. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nINPUT_SIZE = 28\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:32:17.552114Z","iopub.execute_input":"2021-07-05T13:32:17.552443Z","iopub.status.idle":"2021-07-05T13:32:19.995236Z","shell.execute_reply.started":"2021-07-05T13:32:17.552415Z","shell.execute_reply":"2021-07-05T13:32:19.994479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, validation_data=(val_images, val_oh_labels), \n                    epochs=20, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:33:19.360062Z","iopub.execute_input":"2021-07-05T13:33:19.360368Z","iopub.status.idle":"2021-07-05T13:33:41.940452Z","shell.execute_reply.started":"2021-07-05T13:33:19.36034Z","shell.execute_reply":"2021-07-05T13:33:41.93974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])\nprint(history.history['val_loss'])\nprint(history.history['val_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:35:04.807463Z","iopub.execute_input":"2021-07-05T13:35:04.80778Z","iopub.status.idle":"2021-07-05T13:35:04.813416Z","shell.execute_reply.started":"2021-07-05T13:35:04.807751Z","shell.execute_reply":"2021-07-05T13:35:04.812563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='valid')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:35:05.788419Z","iopub.execute_input":"2021-07-05T13:35:05.788738Z","iopub.status.idle":"2021-07-05T13:35:05.966827Z","shell.execute_reply.started":"2021-07-05T13:35:05.788709Z","shell.execute_reply":"2021-07-05T13:35:05.965993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functional API","metadata":{}},{"cell_type":"code","source":"# Sequential Model을 이용하여 Keras 모델 생성 -> 비추\n# Sequential vs Functional API -> 무조건 Functional API로 시작하셈\n# Sequential은 input layer을 구분할 수 없어서 input_shape를 따로 받음\n\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nINPUT_SIZE = 28\n\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()\n\nmodel1 = Sequential()\nmodel1.add(Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)))\nmodel1.add(Dense(100, activation='relu'))\nmodel1.add(Dense(30, activation='relu'))\nmodel1.add(Dense(10, activation='softmax'))\n\nmodel1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:41:37.753855Z","iopub.execute_input":"2021-07-05T13:41:37.754196Z","iopub.status.idle":"2021-07-05T13:41:37.82183Z","shell.execute_reply.started":"2021-07-05T13:41:37.754165Z","shell.execute_reply":"2021-07-05T13:41:37.820674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Functional API: 더 직관적임 \nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE)) # 반드시 input 명시 \nx = Flatten()(input_tensor) # 객체 뒤에 또 인자가 들어감(입력 데이터): layer은 필연적으로 입력을 받음\nx = Dense(100, activation='relu')(x) # 앞에서 나온 아웃풋을 다시 입력으로 넣음 \nx = Dense(30, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x) \n\nmodel = Model(inputs=input_tensor, outputs=output) # input, output\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:41:41.420576Z","iopub.execute_input":"2021-07-05T13:41:41.420889Z","iopub.status.idle":"2021-07-05T13:41:41.456566Z","shell.execute_reply.started":"2021-07-05T13:41:41.42086Z","shell.execute_reply":"2021-07-05T13:41:41.455861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom한 Dense Layer 생성하기","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nclass CustomDense(tf.keras.layers.Layer):\n    # CustomDense 객체 생성시 입력되는 초기화 parameter 처리\n    def __init__(self, units=32):\n        super(CustomDense, self).__init__()\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer=\"random_normal\",\n            trainable=True,\n        )\n        self.b = self.add_weight(\n            shape=(self.units,), initializer=\"random_normal\", trainable=True\n        )\n        \n    # CustomDense 객체에 callable로 입력된 입력 데이터 처리. \n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n\n# input 값을 4개의 원소를 가지는 1차원으로 생성. \ninputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \noutputs = CustomDense(10)(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:34.564759Z","iopub.execute_input":"2021-07-05T13:56:34.565095Z","iopub.status.idle":"2021-07-05T13:56:34.620573Z","shell.execute_reply.started":"2021-07-05T13:56:34.565064Z","shell.execute_reply":"2021-07-05T13:56:34.619607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functional API는 객체 생성 부분과 Callable 인자 입력 부분을 별도로 수행해도 무방. ","metadata":{}},{"cell_type":"code","source":"inputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \nmy_layer = CustomDense(10)\noutputs = my_layer(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:34.789069Z","iopub.execute_input":"2021-07-05T13:56:34.789332Z","iopub.status.idle":"2021-07-05T13:56:34.806363Z","shell.execute_reply.started":"2021-07-05T13:56:34.789307Z","shell.execute_reply":"2021-07-05T13:56:34.805406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model 생성은 단지 Functional API Layer들을 iteration 하면서 연결한 것을 model로 만든 것임","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\n\nmodel = Sequential([Input((4,)),\n                   CustomDense(10),\n                   CustomDense(8), \n                   tf.keras.layers.ReLU()])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:57.705461Z","iopub.execute_input":"2021-07-05T13:56:57.705774Z","iopub.status.idle":"2021-07-05T13:56:57.735275Z","shell.execute_reply.started":"2021-07-05T13:56:57.705743Z","shell.execute_reply":"2021-07-05T13:56:57.734381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model을 Functional 객체를 For loop 반복 호출하여 작성.","metadata":{}},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\nfor index, layer in enumerate(layers_list):\n        print(index, layer)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:58.014691Z","iopub.execute_input":"2021-07-05T13:56:58.014997Z","iopub.status.idle":"2021-07-05T13:56:58.022361Z","shell.execute_reply.started":"2021-07-05T13:56:58.014969Z","shell.execute_reply":"2021-07-05T13:56:58.02089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\ninputs = None\ncallable_inputs = None\noutputs = None\n# layers_list에 있는 Functional 객체를 iteration 수행하면서 적용. \nfor index, layer in enumerate(layers_list):\n    # layers_list의 첫번째 인자는 Input 간주. \n    if index == 0:\n        inputs = layer\n        callable_inputs = layer\n    # Functional 객체에 callable 인자로 callable_inputs를 입력하고 반환 결과 값을 다시 callable_inputs로 할당.     \n    else: \n        callable_inputs = layer(callable_inputs)\n    \noutputs = callable_inputs\nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:58.201737Z","iopub.execute_input":"2021-07-05T13:56:58.201981Z","iopub.status.idle":"2021-07-05T13:56:58.230963Z","shell.execute_reply.started":"2021-07-05T13:56:58.201958Z","shell.execute_reply":"2021-07-05T13:56:58.230162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 앞에서 생성한 로직들을 함수화 \n* Functional API로 모델 만들기\n* pixel값 1 ~ 255를 0 ~ 1사이값 Float 32로 만들기\n* One Hot Encoding Label에 적용하기\n* 학습과 검증 데이터로 나누기.\n* compile, 학습/예측/평가","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.layers import Layer, Input, Dense, Flatten\n# from tensorflow.keras.models import Model\n# import tensorflow as tf\n\n# INPUT_SIZE = 28\n\n# def create_model():\n#     input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n#     x = Flatten()(input_tensor)\n#     x = Dense(100, activation='relu')(x)\n#     x = Dense(30, activation='relu')(x)\n#     output = Dense(10, activation='softmax')(x)\n    \n#     model = Model(inputs=input_tensor, outputs=output)\n#     return model\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:27.707498Z","iopub.execute_input":"2021-07-05T13:56:27.707775Z","iopub.status.idle":"2021-07-05T13:56:27.713847Z","shell.execute_reply.started":"2021-07-05T13:56:27.707748Z","shell.execute_reply":"2021-07-05T13:56:27.71277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\ndef create_model():\n    # 3차원 이미지 input_shape -> 2차원: keras 프레임워크가 개수는 알아서 지정함 \n    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n    x = Flatten()(input_tensor)\n    x = Dense(100, activation='relu')(x)\n    x = Dense(30, activation='relu')(x)\n    output = Dense(10, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output) # multi input/output! \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:00:30.609438Z","iopub.execute_input":"2021-07-05T14:00:30.609806Z","iopub.status.idle":"2021-07-05T14:00:30.617121Z","shell.execute_reply.started":"2021-07-05T14:00:30.609764Z","shell.execute_reply":"2021-07-05T14:00:30.616227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:06:30.899837Z","iopub.execute_input":"2021-07-05T14:06:30.900216Z","iopub.status.idle":"2021-07-05T14:06:30.908098Z","shell.execute_reply.started":"2021-07-05T14:06:30.900187Z","shell.execute_reply":"2021-07-05T14:06:30.906857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:56:28.01416Z","iopub.execute_input":"2021-07-05T13:56:28.014414Z","iopub.status.idle":"2021-07-05T13:56:28.735135Z","shell.execute_reply.started":"2021-07-05T13:56:28.014389Z","shell.execute_reply":"2021-07-05T13:56:28.734174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Model 생성 및 optimizer, loss, metric 적용\nmodel = create_model()\nmodel.summary()\n\n# sparse -> one-hot X\n# categorical -> one-hot \nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:09:43.718917Z","iopub.execute_input":"2021-07-05T14:09:43.719358Z","iopub.status.idle":"2021-07-05T14:09:43.761763Z","shell.execute_reply.started":"2021-07-05T14:09:43.719327Z","shell.execute_reply":"2021-07-05T14:09:43.760755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 학습 수행. \nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=20, validation_data=(val_images, val_oh_labels)) # 모델학습에서 x는 3차원 데이터로 들어감 \n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:09:46.874969Z","iopub.execute_input":"2021-07-05T14:09:46.877465Z","iopub.status.idle":"2021-07-05T14:10:08.577667Z","shell.execute_reply.started":"2021-07-05T14:09:46.877422Z","shell.execute_reply":"2021-07-05T14:10:08.576968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:12:09.560958Z","iopub.execute_input":"2021-07-05T14:12:09.561296Z","iopub.status.idle":"2021-07-05T14:12:09.718474Z","shell.execute_reply.started":"2021-07-05T14:12:09.561266Z","shell.execute_reply":"2021-07-05T14:12:09.717603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 세트로 모델 성능 검증\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1) # 주의! 여기서도 원핫인코딩된 값을 넣어야 함","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:12:13.916157Z","iopub.execute_input":"2021-07-05T14:12:13.916474Z","iopub.status.idle":"2021-07-05T14:12:14.067045Z","shell.execute_reply.started":"2021-07-05T14:12:13.916445Z","shell.execute_reply":"2021-07-05T14:12:14.066195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callback ","metadata":{}},{"cell_type":"markdown","source":"#### ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n* 특정 조건에 맞춰서 모델을 파일로 저장\n* filepath: filepath는 (on_epoch_end에서 전달되는) epoch의 값과 logs의 키로 채워진 이름 형식 옵션을 가질 수 있음.\n예를 들어 filepath가 weights.{epoch:02d}-{val_loss:.2f}.hdf5라면, 파일 이름에 세대 번호와 검증 손실을 넣어 모델의 체크포인트가 저장 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* save_best_only: 가장 좋은 성능을 나타내는 모델만 저장할 여부\n* save_weights_only: Weights만 저장할 지 여부 \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 자동으로 유추. ","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:22:38.183331Z","iopub.execute_input":"2021-07-05T14:22:38.183645Z","iopub.status.idle":"2021-07-05T14:22:38.85378Z","shell.execute_reply.started":"2021-07-05T14:22:38.183616Z","shell.execute_reply":"2021-07-05T14:22:38.85291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=3, verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=10, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:22:39.852721Z","iopub.execute_input":"2021-07-05T14:22:39.853066Z","iopub.status.idle":"2021-07-05T14:22:51.051111Z","shell.execute_reply.started":"2021-07-05T14:22:39.853014Z","shell.execute_reply":"2021-07-05T14:22:51.050318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia\n#!rm -rf weight*\n#!ls -lia\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:22:53.179302Z","iopub.execute_input":"2021-07-05T14:22:53.179624Z","iopub.status.idle":"2021-07-05T14:22:53.934569Z","shell.execute_reply.started":"2021-07-05T14:22:53.179593Z","shell.execute_reply":"2021-07-05T14:22:53.933358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n* 특정 epochs 횟수동안 성능이 개선 되지 않을 시 Learning rate를 동적으로 감소 시킴 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* factor: 학습 속도를 줄일 인수. new_lr = lr * factor \n* patience: Learing Rate를 줄이기 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[rlr_cb])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:24:36.329944Z","iopub.execute_input":"2021-07-05T14:24:36.330306Z","iopub.status.idle":"2021-07-05T14:25:09.23731Z","shell.execute_reply.started":"2021-07-05T14:24:36.330274Z","shell.execute_reply":"2021-07-05T14:25:09.236467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n* 특정 epochs 동안 성능이 개선되지 않을 시 학습을 조기에 중단\n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* patience: Early Stopping 적용 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nely_cb = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[ely_cb])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:25:21.165748Z","iopub.execute_input":"2021-07-05T14:25:21.166093Z","iopub.status.idle":"2021-07-05T14:25:35.537107Z","shell.execute_reply.started":"2021-07-05T14:25:21.166056Z","shell.execute_reply":"2021-07-05T14:25:35.536161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm weigh*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 보통 세 개의 callback 다같이 씀 \nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=1, verbose=0)\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=40, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb, rlr_cb, ely_cb])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T14:27:00.624396Z","iopub.execute_input":"2021-07-05T14:27:00.624718Z","iopub.status.idle":"2021-07-05T14:27:27.172574Z","shell.execute_reply.started":"2021-07-05T14:27:00.624688Z","shell.execute_reply":"2021-07-05T14:27:27.171886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lia","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}